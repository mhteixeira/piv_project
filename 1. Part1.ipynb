{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Localization from one camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup import parse_config_file\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import io\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import cv2 \n",
    "from cv2 import DMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting features from video\n",
    "\n",
    "This function implements the SIFT algorithm to find keypoints of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(vid_capture, frames_to_process):\n",
    "    features = np.zeros((1, frames_to_process), dtype=object)\n",
    "    frames = []\n",
    "    keypoints_array = []\n",
    "    current_frame = 0 \n",
    "    while(vid_capture.isOpened()):\n",
    "        # vid_capture.read() methods returns a tuple, first element is a bool \n",
    "        # and the second is frame\n",
    "        for _ in range(100):\n",
    "            ret, frame = vid_capture.read()\n",
    "            \n",
    "        sift = cv2.SIFT_create()\n",
    "        if ret == True:\n",
    "            # getting keypoints and descriptor\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            keypoints, descriptor = sift.detectAndCompute(frame_gray, None)\n",
    "            keypoints_array.append(keypoints)\n",
    "\n",
    "            # getting the location of each keypoint\n",
    "            x_location = []\n",
    "            y_location = []\n",
    "            for keypoint in keypoints:\n",
    "                x_location.append(keypoint.pt[0])\n",
    "                y_location.append(keypoint.pt[1])\n",
    "            ## (x, y, d)\n",
    "            concatenation = np.insert(np.transpose(descriptor), [0, 1], [x_location, y_location], axis=0)\n",
    "            #print(f'concatenation: {np.shape(concatenation)}') \n",
    "            features[0, current_frame] = concatenation\n",
    "\n",
    "            current_frame += 1\n",
    "            frames.append(frame)\n",
    "            static_frame = cv2.drawKeypoints(frame, keypoints, None, color=(0, 255, 0))\n",
    "            cv2.imshow('Static Keypoints', static_frame)\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            if current_frame == frames_to_process:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    # print(features.shape)\n",
    "    vid_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return features, frames, keypoints_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding matches from keypoint descriptors from two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features(features1, features2, matches_size = 100, num_features= 64):\n",
    "    C = np.vstack((features1, features2))\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=num_features)\n",
    "    reconstructed = pca.fit_transform(C)\n",
    "    \n",
    "    features1 = reconstructed[:len(features1), :]\n",
    "    features2 = reconstructed[len(features1):, :]\n",
    "    \n",
    "    # Euclidean distance\n",
    "    D = cdist(features1, features2, 'euclidean')\n",
    "    \n",
    "    # Sorting distances and finding nearest neighbors\n",
    "    I = np.argsort(D, axis=1)\n",
    "    nearest_neighbor = D[np.arange(len(D)), I[:, 0]]\n",
    "    second_nearest_neighbor = D[np.arange(len(D)), I[:, 1]]\n",
    "    confidences = nearest_neighbor / second_nearest_neighbor\n",
    "    \n",
    "    # Filtering non-zero confidences\n",
    "    i = np.where(confidences)[0]\n",
    "    matches = np.column_stack((i, I[i]))\n",
    "    confidences = 1.0 / confidences[i]\n",
    "    \n",
    "    # Sorting by confidence and selecting top 100 matches\n",
    "    sorted_indices = np.argsort(confidences)[::-1]\n",
    "    matches = matches[sorted_indices][:matches_size, :]\n",
    "    confidences = confidences[sorted_indices][:matches_size]\n",
    "\n",
    "    matches = [DMatch(_queryIdx=int(match[0]), \n",
    "                      _trainIdx=int(match[1]), \n",
    "                      _distance=float(D[int(match[0]), int(match[1])])) \n",
    "                          for match in matches]\n",
    "    \n",
    "    return matches, confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating homography matrix  from sets of points\n",
    "\n",
    "From two sets of points this function compute the homography between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_homography_matrix(src_points, dst_points):\n",
    "    A = []\n",
    "    b = [] \n",
    "    for i in range(len(src_points)):\n",
    "        x, y = src_points[i]\n",
    "        u, v = dst_points[i]\n",
    "        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y])\n",
    "        A.append([0, 0, 0, x, y, 1, -v*x, -v*y])\n",
    "\n",
    "        b.append(u)\n",
    "        b.append(v)\n",
    "\n",
    "    A = np.array(A)\n",
    "\n",
    "    h = np.dot((np.dot(np.linalg.inv(np.dot(A.T,A)),A.T)), b)\n",
    "    h = np.append(h, 1) \n",
    "    h = h.reshape(3,3)\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homography from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homographies_from_features(vid_capture, features, frames_to_process):\n",
    "    homographies = []\n",
    "    for i in range(frames_to_process):\n",
    "        for j in range(i+1, frames_to_process):\n",
    "            matches, confidences = match_features(np.transpose(features[0, i][2:]), np.transpose(features[0, j][2:]), matches_size=100)\n",
    "\n",
    "            src_points = []\n",
    "            dst_points = []\n",
    "            matched_img = cv2.drawMatches(frames[i], keypoints_array[i], frames[j], keypoints_array[j], matches, None, flags=2)\n",
    "            h, w, _ = matched_img.shape\n",
    "            matched_img = cv2.resize(matched_img, (int(3*w/4), int(3*h/4)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.imshow('Static Keypoints', matched_img)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            for match in matches:\n",
    "                src_points.append(features[0, i][0:2, match.queryIdx])\n",
    "                dst_points.append(features[0, j][0:2, match.trainIdx])\n",
    "                \n",
    "            homography = [i+1, j+1]\n",
    "            homography.extend(create_homography_matrix(src_points, dst_points).flatten())\n",
    "            homographies.append(homography)\n",
    "    cv2.destroyAllWindows()\n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homography from corresponding points (map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homographies_from_corresponding_points(pts_in_map_from_config, pts_in_frame_from_config):\n",
    "    homographies = []\n",
    "    for i in range(len(pts_in_map_from_config)):\n",
    "        pts_in_map = np.array(pts_in_map_from_config[i][1:], dtype=float)\n",
    "        pts_in_map = pts_in_map.reshape(int(len(pts_in_map)/2), 2)\n",
    "        pts_in_frame = np.array(pts_in_frame_from_config[i][1:], dtype=float)\n",
    "        pts_in_frame = pts_in_frame.reshape(int(len(pts_in_frame)/2), 2)\n",
    "        homography = [0, int(pts_in_frame_from_config[i][0])]\n",
    "        homography.extend(create_homography_matrix(pts_in_map, pts_in_frame).flatten())\n",
    "        homographies.append(homography)\n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `processing_video.py` main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./conf_file.cpg\"\n",
    "config = parse_config_file(config_path)\n",
    "\n",
    "vid_capture = cv2.VideoCapture(config['videos'])\n",
    "frames_to_process = 5\n",
    "\n",
    "features, frames, keypoints_array = get_features(vid_capture, frames_to_process)\n",
    "data={'features': features}\n",
    "io.savemat(config['keypoints_out'], data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `compute_transform.py` main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./conf_file.cpg\"\n",
    "config = parse_config_file(config_path)\n",
    "\n",
    "vid_capture = cv2.VideoCapture(config['videos'])\n",
    "frames_to_process = 5\n",
    "\n",
    "if config['transforms'][0][0] == 'homography':\n",
    "    if config['transforms'][0][1] == 'all':\n",
    "        homographies = homographies_from_features(vid_capture, features, frames_to_process)\n",
    "    elif config['transforms'][0][1] == 'map':\n",
    "        if len(config['pts_in_map']) != len(config['pts_in_frame']):\n",
    "            print(\"Different amount of pts_in_map and pts_in_frame defined inside the config file\")\n",
    "            sys.exit(1)\n",
    "        homographies = homographies_from_corresponding_points(config['pts_in_map'], config['pts_in_frame'])\n",
    "    data={'transforms': np.array(homographies).transpose()}\n",
    "    io.savemat(config['transforms_out'], data)\n",
    "else:\n",
    "    print(\"The only acceptable type is \\\"homography\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
