{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Localization from one camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.setup import parse_config_file\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import io\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import cv2 \n",
    "from cv2 import DMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting features from video\n",
    "\n",
    "This function implements the SIFT algorithm to find keypoints of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(vid_capture, frames_to_process):\n",
    "    features = np.zeros((1, frames_to_process), dtype=object)\n",
    "    frames = []\n",
    "    keypoints_array = []\n",
    "    current_frame = 0 \n",
    "    while(vid_capture.isOpened()):\n",
    "        # vid_capture.read() methods returns a tuple, first element is a bool \n",
    "        # and the second is frame\n",
    "        for _ in range(100):\n",
    "            ret, frame = vid_capture.read()\n",
    "            \n",
    "        sift = cv2.SIFT_create()\n",
    "        if ret == True:\n",
    "            # getting keypoints and descriptor\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            keypoints, descriptor = sift.detectAndCompute(frame_gray, None)\n",
    "            keypoints_array.append(keypoints)\n",
    "\n",
    "            # getting the location of each keypoint\n",
    "            x_location = []\n",
    "            y_location = []\n",
    "            for keypoint in keypoints:\n",
    "                x_location.append(keypoint.pt[0])\n",
    "                y_location.append(keypoint.pt[1])\n",
    "            ## (x, y, d)\n",
    "            concatenation = np.insert(np.transpose(descriptor), [0, 1], [x_location, y_location], axis=0)\n",
    "            #print(f'concatenation: {np.shape(concatenation)}') \n",
    "            features[0, current_frame] = concatenation\n",
    "\n",
    "            current_frame += 1\n",
    "            frames.append(frame)\n",
    "            static_frame = cv2.drawKeypoints(frame, keypoints, None, color=(0, 255, 0))\n",
    "            cv2.imwrite(f\"./debugfiles/keypoints/{config['videos'].split('.mp4')[0].split('/')[1]}_keypoints_frame_{current_frame}.png\", static_frame)\n",
    "            cv2.imshow('Static Keypoints', static_frame)\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            if current_frame == frames_to_process:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    # print(features.shape)\n",
    "    vid_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return features, frames, keypoints_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding matches from keypoint descriptors from two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features(features1, features2, matches_size = 100, num_features= 64):\n",
    "    C = np.vstack((features1, features2))\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=num_features)\n",
    "    reconstructed = pca.fit_transform(C)\n",
    "    \n",
    "    features1 = reconstructed[:len(features1), :]\n",
    "    features2 = reconstructed[len(features1):, :]\n",
    "    \n",
    "    # Euclidean distance\n",
    "    D = cdist(features1, features2, 'euclidean')\n",
    "    \n",
    "    # Sorting distances and finding nearest neighbors\n",
    "    I = np.argsort(D, axis=1)\n",
    "    nearest_neighbor = D[np.arange(len(D)), I[:, 0]]\n",
    "    second_nearest_neighbor = D[np.arange(len(D)), I[:, 1]]\n",
    "    confidences = nearest_neighbor / second_nearest_neighbor\n",
    "    \n",
    "    # Filtering non-zero confidences\n",
    "    i = np.where(confidences)[0]\n",
    "    matches = np.column_stack((i, I[i]))\n",
    "    confidences = 1.0 / confidences[i]\n",
    "    \n",
    "    # Sorting by confidence and selecting top 100 matches\n",
    "    sorted_indices = np.argsort(confidences)[::-1]\n",
    "    matches = matches[sorted_indices][:matches_size, :]\n",
    "    confidences = confidences[sorted_indices][:matches_size]\n",
    "\n",
    "    matches = [DMatch(_queryIdx=int(match[0]), \n",
    "                      _trainIdx=int(match[1]), \n",
    "                      _distance=float(D[int(match[0]), int(match[1])])) \n",
    "                          for match in matches]\n",
    "    \n",
    "    return matches, confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating homography matrix  from sets of points\n",
    "\n",
    "From two sets of points this function compute the homography between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_homography_matrix(src_points, dst_points):\n",
    "    A = []\n",
    "    b = [] \n",
    "    for i in range(len(src_points)):\n",
    "        x, y = src_points[i]\n",
    "        u, v = dst_points[i]\n",
    "        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y])\n",
    "        A.append([0, 0, 0, x, y, 1, -v*x, -v*y])\n",
    "\n",
    "        b.append(u)\n",
    "        b.append(v)\n",
    "    try:\n",
    "        A = np.array(A)\n",
    "        h = np.dot((np.dot(np.linalg.inv(np.dot(A.T,A)),A.T)), b)\n",
    "        h = np.append(h, 1) \n",
    "        h = h.reshape(3,3)\n",
    "    except Exception as e:\n",
    "        rollbar.report_exc_info()\n",
    "        exit()\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homography from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homographies_from_features(features, frames_to_process):\n",
    "    homographies = []\n",
    "    for i in range(frames_to_process):\n",
    "        for j in range(i+1, frames_to_process):\n",
    "            matches, confidences = match_features(np.transpose(features[0, i][2:]), np.transpose(features[0, j][2:]), matches_size=100)\n",
    "\n",
    "            src_points = []\n",
    "            dst_points = []\n",
    "\n",
    "            for match in matches:\n",
    "                src_points.append(features[0, i][0:2, match.queryIdx])\n",
    "                dst_points.append(features[0, j][0:2, match.trainIdx])\n",
    "                \n",
    "            homography = [i+1, j+1]\n",
    "            homography_matrix = create_homography_matrix(src_points, dst_points)\n",
    "\n",
    "            homography.extend(homography_matrix.flatten())\n",
    "            homographies.append(homography)\n",
    "            \n",
    "            matched_img = cv2.drawMatches(frames[i], keypoints_array[i], frames[j], keypoints_array[j], matches, None, flags=2)\n",
    "            h, w, _ = matched_img.shape\n",
    "            matched_img = cv2.resize(matched_img, (int(3*w/4), int(3*h/4)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.putText(matched_img, f\"{i}, {j}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.imwrite(f\"./debugfiles/matches/{config['videos'].split('.mp4')[0].split('/')[1]}_matches_frame_{i+1}_{j+1}.png\", matched_img)\n",
    "            cv2.imshow('Matches', matched_img)\n",
    "\n",
    "            img_i = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "            img_j = cv2.cvtColor(frames[j], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Warp img_i to img_j using the computed homography\n",
    "            img_i_warped = cv2.warpPerspective(img_i, homography_matrix, (img_j.shape[1], img_j.shape[0]))\n",
    "\n",
    "            # Concatenate the two images side by side for visualization\n",
    "            concatenated_imgs = np.concatenate((img_j, img_i_warped), axis=1)\n",
    "            h, w = concatenated_imgs.shape\n",
    "            concatenated_imgs = cv2.resize(concatenated_imgs, (int(1*w/2), int(1*h/2)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.imwrite(f\"./debugfiles/homography/{config['videos'].split('.mp4')[0].split('/')[1]}_homography_frame_{i+1}_{j+1}.png\", concatenated_imgs)\n",
    "            cv2.imshow(f\"Homography\", concatenated_imgs)\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homography from corresponding points (map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homographies_from_corresponding_points(pts_in_map_from_config, pts_in_frame_from_config):\n",
    "    homographies = []\n",
    "    for i in range(len(pts_in_map_from_config)):\n",
    "        pts_in_map = np.array(pts_in_map_from_config[i][1:], dtype=float)\n",
    "        pts_in_map = pts_in_map.reshape(int(len(pts_in_map)/2), 2)\n",
    "        pts_in_frame = np.array(pts_in_frame_from_config[i][1:], dtype=float)\n",
    "        pts_in_frame = pts_in_frame.reshape(int(len(pts_in_frame)/2), 2)\n",
    "        homography = [0, int(pts_in_frame_from_config[i][0])]\n",
    "        homography.extend(create_homography_matrix(pts_in_map, pts_in_frame).flatten())\n",
    "        homographies.append(homography)\n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `processing_video.py` main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./conf_file.cpg\"\n",
    "config = parse_config_file(config_path)\n",
    "\n",
    "vid_capture = cv2.VideoCapture(config['videos'])\n",
    "frames_to_process = 5\n",
    "\n",
    "features, frames, keypoints_array = get_features(vid_capture, frames_to_process)\n",
    "data={'features': features}\n",
    "io.savemat(config['keypoints_out'], data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `compute_transform.py` main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./conf_file.cpg\"\n",
    "config = parse_config_file(config_path)\n",
    "\n",
    "if config['transforms'][0][0] == 'homography':\n",
    "    if config['transforms'][0][1] == 'all':\n",
    "        homographies = homographies_from_features(features, frames_to_process)\n",
    "    elif config['transforms'][0][1] == 'map':\n",
    "        if len(config['pts_in_map']) != len(config['pts_in_frame']):\n",
    "            print(\"Different amount of pts_in_map and pts_in_frame defined inside the config file\")\n",
    "            sys.exit(1)\n",
    "        homographies = homographies_from_corresponding_points(config['pts_in_map'], config['pts_in_frame'])\n",
    "    data={'transforms': np.array(homographies).transpose()}\n",
    "    io.savemat(config['transforms_out'], data)\n",
    "else:\n",
    "    print(\"The only acceptable type is \\\"homography\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing RANSAC to remove outliers\n",
    "WORKING..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_homography_custom(src_points, dst_points, i, j, iterations=100, threshold=5.0):\n",
    "    src_points = np.array(src_points)\n",
    "    dst_points = np.array(dst_points)\n",
    "    best_homography = None\n",
    "    max_inliers = 0\n",
    "    n_points = src_points.shape[0]\n",
    "    best_projects = None\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # Randomly select 4 points for homography computation\n",
    "        indices = np.random.choice(n_points, 4, replace=False)\n",
    "        src_sample = src_points[indices]\n",
    "        dst_sample = dst_points[indices]\n",
    "\n",
    "        \n",
    "        # Estimate homography using these points\n",
    "        try:\n",
    "            H = create_homography_matrix(src_sample, dst_sample)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Project src_points using the estimated homography\n",
    "        ones = np.ones((n_points, 1))\n",
    "        homogeneous_src_points = np.hstack([src_points, ones])\n",
    "        projected_points = (H @ homogeneous_src_points.T).T\n",
    "        projected_points = projected_points[:, :2] / projected_points[:, [2]]\n",
    "\n",
    "        # Calculate distances between projected and actual destination points\n",
    "        distances = np.sqrt(np.sum((projected_points - dst_points) ** 2, axis=1))\n",
    "\n",
    "        # Count inliers\n",
    "        inliers_count = np.sum(distances < threshold)\n",
    "\n",
    "        # Update the best homography matrix if more inliers are found\n",
    "        if inliers_count > max_inliers:\n",
    "            best_homography = H.copy()\n",
    "            max_inliers = inliers_count\n",
    "            best_projects = projected_points\n",
    "\n",
    "        # img_i = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "        # img_j = cv2.cvtColor(frames[j], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # # Warp img_i to img_j using the computed homography\n",
    "        # img_i_warped = cv2.warpPerspective(img_i, H, (img_j.shape[1], img_j.shape[0]))\n",
    "\n",
    "        # # Concatenate the two images side by side for visualization\n",
    "        # concatenated_imgs = np.concatenate((img_j, img_i_warped), axis=1)\n",
    "        # h, w = concatenated_imgs.shape\n",
    "        # concatenated_imgs = cv2.resize(concatenated_imgs, (int(1*w/2), int(1*h/2)), interpolation = cv2.INTER_LINEAR)\n",
    "        # cv2.imshow(f\"Homography RANSAC\", concatenated_imgs)\n",
    "\n",
    "    # Re-estimate homography using all inliers if a model was found\n",
    "    if best_homography is not None:\n",
    "        inliers = np.sqrt(np.sum((best_projects - dst_points) ** 2, axis=1)) < threshold\n",
    "        best_homography = create_homography_matrix(src_points[inliers], dst_points[inliers])\n",
    "\n",
    "    return np.array(best_homography), inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def homographies_from_features(features, frames_to_process):\n",
    "    homographies = []\n",
    "    for i in range(frames_to_process):\n",
    "        for j in range(i+1, frames_to_process):\n",
    "            matches, confidences = match_features(np.transpose(features[0, i][2:]), np.transpose(features[0, j][2:]), matches_size=100)\n",
    "\n",
    "            src_points = []\n",
    "            dst_points = []\n",
    "\n",
    "            for match in matches:\n",
    "                src_points.append(features[0, i][0:2, match.queryIdx])\n",
    "                dst_points.append(features[0, j][0:2, match.trainIdx])\n",
    "                \n",
    "            homography = [i+1, j+1]\n",
    "            homography_matrix, _ = ransac_homography_custom(src_points, dst_points, i, j, 5000)\n",
    "            Homography_cv, mask = cv2.findHomography(np.array(src_points), np.array(dst_points), cv2.RANSAC, 5.0)\n",
    "            \n",
    "            homography.extend(homography_matrix.flatten())\n",
    "            homographies.append(homography)\n",
    "            \n",
    "            matched_img = cv2.drawMatches(frames[i], keypoints_array[i], frames[j], keypoints_array[j], matches, None, flags=2)\n",
    "            h, w, _ = matched_img.shape\n",
    "            matched_img = cv2.resize(matched_img, (int(3*w/4), int(3*h/4)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.putText(matched_img, f\"{i}, {j}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.imwrite(f\"./debugfiles/matches/{config['videos'].split('.mp4')[0].split('/')[1]}_matches_frame_{i+1}_{j+1}_R.png\", matched_img)\n",
    "            cv2.imshow('Matches', matched_img)\n",
    "\n",
    "            img_i = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "            img_j = cv2.cvtColor(frames[j], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Warp img_i to img_j using the computed homography\n",
    "            img_i_warped = cv2.warpPerspective(img_j, homography_matrix, (img_j.shape[1], img_j.shape[0]))\n",
    "            img_open_cv = cv2.warpPerspective(img_j, Homography_cv, (img_j.shape[1], img_j.shape[0]))\n",
    "\n",
    "            cv2.putText(img_i, \"Original image\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(img_i_warped, \"Custom H\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(img_open_cv, \"Open CV H\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            # Concatenate the two images side by side for visualization\n",
    "            concatenated_imgs = np.concatenate((img_i, img_i_warped, img_open_cv), axis=1)\n",
    "            h, w = concatenated_imgs.shape\n",
    "            concatenated_imgs = cv2.resize(concatenated_imgs, (int(1*w/2), int(1*h/2)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.imwrite(f\"./debugfiles/homography/{config['videos'].split('.mp4')[0].split('/')[1]}_homography_frame_{i+1}_{j+1}_R.png\", concatenated_imgs)\n",
    "            cv2.imshow(f\"Homography\", concatenated_imgs)\n",
    "            \n",
    "            if cv2.waitKey(60) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `compute_transform.py` main now with RANSAC\n",
    "\n",
    "WORKING..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./conf_file.cpg\"\n",
    "config = parse_config_file(config_path)\n",
    "\n",
    "if config['transforms'][0][0] == 'homography':\n",
    "    if config['transforms'][0][1] == 'all':\n",
    "        homographies = homographies_from_features( features, frames_to_process)\n",
    "    elif config['transforms'][0][1] == 'map':\n",
    "        if len(config['pts_in_map']) != len(config['pts_in_frame']):\n",
    "            print(\"Different amount of pts_in_map and pts_in_frame defined inside the config file\")\n",
    "            sys.exit(1)\n",
    "        homographies = homographies_from_corresponding_points(config['pts_in_map'], config['pts_in_frame'])\n",
    "    data={'transforms': np.array(homographies).transpose()}\n",
    "    io.savemat(config['transforms_out'], data)\n",
    "else:\n",
    "    print(\"The only acceptable type is \\\"homography\\\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
