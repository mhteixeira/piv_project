{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Localization from one camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.setup import parse_config_file\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import io\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import cv2 \n",
    "from cv2 import DMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting features from video\n",
    "\n",
    "This function implements the SIFT algorithm to find keypoints of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(vid_capture, frames_to_process):\n",
    "    features = np.zeros((1, frames_to_process), dtype=object)\n",
    "    frames = []\n",
    "    keypoints_array = []\n",
    "    current_frame = 0 \n",
    "    while(vid_capture.isOpened()):\n",
    "        # vid_capture.read() methods returns a tuple, first element is a bool \n",
    "        # and the second is frame\n",
    "        for _ in range(100):\n",
    "            ret, frame = vid_capture.read()\n",
    "            \n",
    "        sift = cv2.SIFT_create(nfeatures=1000)\n",
    "        if ret == True:\n",
    "            # getting keypoints and descriptor\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            # Equalize the distribution of the image\n",
    "            frame_equalize = cv2.equalizeHist(frame_gray)\n",
    "            keypoints, descriptor = sift.detectAndCompute(frame_equalize, None)\n",
    "            keypoints_array.append(keypoints)\n",
    "\n",
    "            # getting the location of each keypoint\n",
    "            x_location = []\n",
    "            y_location = []\n",
    "            for keypoint in keypoints:\n",
    "                x_location.append(keypoint.pt[0])\n",
    "                y_location.append(keypoint.pt[1])\n",
    "            ## (x, y, d)\n",
    "            concatenation = np.insert(np.transpose(descriptor), [0, 1], [x_location, y_location], axis=0)\n",
    "            #print(f'concatenation: {np.shape(concatenation)}') \n",
    "            features[0, current_frame] = concatenation\n",
    "\n",
    "            current_frame += 1\n",
    "            frames.append(frame)\n",
    "            static_frame = cv2.drawKeypoints(frame, keypoints, None, color=(0, 255, 0))\n",
    "            cv2.imwrite(f\"./debugfiles/keypoints/{config['videos'].split('.mp4')[0].split('/')[1]}_keypoints_frame_{current_frame}.png\", static_frame)\n",
    "            cv2.imshow('Static Keypoints', static_frame)\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            if current_frame == frames_to_process:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    # print(features.shape)\n",
    "    vid_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return features, frames, keypoints_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding matches from keypoint descriptors from two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features(features1, features2, matches_size = 100):\n",
    "    # Euclidean distance\n",
    "    D = cdist(features1, features2, 'euclidean')\n",
    "    \n",
    "    # Sorting distances and finding nearest neighbors\n",
    "    I = np.argsort(D, axis=1)\n",
    "    nearest_neighbor = D[np.arange(len(D)), I[:, 0]]\n",
    "    second_nearest_neighbor = D[np.arange(len(D)), I[:, 1]]\n",
    "    confidences = nearest_neighbor / second_nearest_neighbor\n",
    "    \n",
    "    # Filtering non-zero confidences\n",
    "    i = np.where(confidences)[0]\n",
    "    matches = np.column_stack((i, I[i]))\n",
    "    confidences = 1.0 / confidences[i]\n",
    "    \n",
    "    # Sorting by confidence and selecting top 100 matches\n",
    "    sorted_indices = np.argsort(confidences)[::-1]\n",
    "    matches = matches[sorted_indices][:matches_size, :]\n",
    "    confidences = confidences[sorted_indices][:matches_size]\n",
    "\n",
    "    matches = [DMatch(_queryIdx=int(match[0]), \n",
    "                      _trainIdx=int(match[1]), \n",
    "                      _distance=float(D[int(match[0]), int(match[1])])) \n",
    "                          for match in matches]\n",
    "    \n",
    "    return matches, confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating homography matrix  from sets of points\n",
    "\n",
    "From two sets of points this function compute the homography between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import eig\n",
    "\n",
    "def create_homography_matrix(src_points, dst_points):\n",
    "    A = []\n",
    "    b = [] \n",
    "    for i in range(len(src_points)):\n",
    "        x, y = src_points[i]\n",
    "        u, v = dst_points[i]\n",
    "        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y, -u])\n",
    "        A.append([0, 0, 0, x, y, 1, -v*x, -v*y, -v])\n",
    "    try:\n",
    "        A = np.array(A)\n",
    "        _, _, V = np.linalg.svd(A)\n",
    "        h = V[-1, :]\n",
    "        h = h.reshape(3,3)\n",
    "        return h\n",
    "    except Exception as e:\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homography from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homographies_from_features(features, frames_to_process):\n",
    "    homographies = []\n",
    "    for i in range(frames_to_process):\n",
    "        for j in range(i+1, frames_to_process):\n",
    "            matches, confidences = match_features(np.transpose(features[0, i][2:]), np.transpose(features[0, j][2:]), matches_size=100)\n",
    "\n",
    "            src_points = []\n",
    "            dst_points = []\n",
    "\n",
    "            for match in matches:\n",
    "                src_points.append(features[0, i][0:2, match.queryIdx])\n",
    "                dst_points.append(features[0, j][0:2, match.trainIdx])\n",
    "                \n",
    "            homography = [i+1, j+1]\n",
    "            homography_matrix = create_homography_matrix(src_points, dst_points)\n",
    "            homography.extend(homography_matrix.flatten())\n",
    "            homographies.append(homography)\n",
    "            \n",
    "            matched_img = cv2.drawMatches(frames[i], keypoints_array[i], frames[j], keypoints_array[j], matches, None, flags=2)\n",
    "            h, w, _ = matched_img.shape\n",
    "            matched_img = cv2.resize(matched_img, (int(3*w/4), int(3*h/4)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.putText(matched_img, f\"{i}, {j}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.imwrite(f\"./debugfiles/matches/{config['videos'].split('.mp4')[0].split('/')[1]}_matches_frame_{i+1}_{j+1}.png\", matched_img)\n",
    "            cv2.imshow('Matches', matched_img)\n",
    "\n",
    "            img_i = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "            img_j = cv2.cvtColor(frames[j], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Warp img_i to img_j using the computed homography\n",
    "            img_i_warped = cv2.warpPerspective(img_i, homography_matrix, (img_j.shape[1], img_j.shape[0]))\n",
    "\n",
    "            # Concatenate the two images side by side for visualization\n",
    "            concatenated_imgs = np.concatenate((img_j, img_i_warped), axis=1)\n",
    "            h, w = concatenated_imgs.shape\n",
    "            concatenated_imgs = cv2.resize(concatenated_imgs, (int(1*w/2), int(1*h/2)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.imwrite(f\"./debugfiles/homography/{config['videos'].split('.mp4')[0].split('/')[1]}_homography_frame_{i+1}_{j+1}.png\", concatenated_imgs)\n",
    "            cv2.imshow(f\"Homography\", concatenated_imgs)\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homography from corresponding points (map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homographies_from_corresponding_points(pts_in_map_from_config, pts_in_frame_from_config):\n",
    "    homographies = []\n",
    "    for i in range(len(pts_in_map_from_config)):\n",
    "        pts_in_map = np.array(pts_in_map_from_config[i][1:], dtype=float)\n",
    "        pts_in_map = pts_in_map.reshape(int(len(pts_in_map)/2), 2)\n",
    "        pts_in_frame = np.array(pts_in_frame_from_config[i][1:], dtype=float)\n",
    "        pts_in_frame = pts_in_frame.reshape(int(len(pts_in_frame)/2), 2)\n",
    "        homography = [0, int(pts_in_frame_from_config[i][0])]\n",
    "        homography.extend(create_homography_matrix(pts_in_map, pts_in_frame).flatten())\n",
    "        homographies.append(homography)\n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `processing_video.py` main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./conf_file.cpg\"\n",
    "config = parse_config_file(config_path)\n",
    "\n",
    "vid_capture = cv2.VideoCapture(config['videos'])\n",
    "frames_to_process = 5\n",
    "\n",
    "features, frames, keypoints_array = get_features(vid_capture, frames_to_process)\n",
    "data={'features': features}\n",
    "io.savemat(config['keypoints_out'], data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `compute_transform.py` main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert None (type <class 'NoneType'>) to array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(homographies)\n\u001b[0;32m     38\u001b[0m     data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(homographies)\u001b[38;5;241m.\u001b[39mtranspose()}\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavemat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransforms_out\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe only acceptable type is \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mhomography\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\io\\matlab\\_mio.py:300\u001b[0m, in \u001b[0;36msavemat\u001b[1;34m(file_name, mdict, appendmat, format, long_field_names, do_compression, oned_as)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat should be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 300\u001b[0m \u001b[43mMW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\io\\matlab\\_mio5.py:895\u001b[0m, in \u001b[0;36mMatFile5Writer.put_variables\u001b[1;34m(self, mdict, write_header)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mwrite(out_str)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# not compressing\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_top\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_global\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\io\\matlab\\_mio5.py:636\u001b[0m, in \u001b[0;36mVarWriter5.write_top\u001b[1;34m(self, arr, name, is_global)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    635\u001b[0m \u001b[38;5;66;03m# write the header and data\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\io\\matlab\\_mio5.py:667\u001b[0m, in \u001b[0;36mVarWriter5.write\u001b[1;34m(self, arr)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_struct(narr)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m narr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mhasobject:  \u001b[38;5;66;03m# cell array\u001b[39;00m\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_cells\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnarr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m narr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39municode_strings:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\io\\matlab\\_mio5.py:772\u001b[0m, in \u001b[0;36mVarWriter5.write_cells\u001b[1;34m(self, arr)\u001b[0m\n\u001b[0;32m    770\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(arr)\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m A:\n\u001b[1;32m--> 772\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\io\\matlab\\_mio5.py:656\u001b[0m, in \u001b[0;36mVarWriter5.write\u001b[1;34m(self, arr)\u001b[0m\n\u001b[0;32m    654\u001b[0m narr \u001b[38;5;241m=\u001b[39m to_writeable(arr)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m narr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) to array\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    657\u001b[0m                     \u001b[38;5;241m%\u001b[39m (arr, \u001b[38;5;28mtype\u001b[39m(arr)))\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(narr, MatlabObject):\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_object(narr)\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert None (type <class 'NoneType'>) to array"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "config_path = \"./conf_file.cpg\"\n",
    "config = parse_config_file(config_path)\n",
    "\n",
    "def homographies_from_map(features, frame_to_process, pts_in_map, pts_in_frame):\n",
    "    homographies_between_frames = np.array(homographies_from_features(features, frame_to_process))\n",
    "    homographies = np.array(homographies_from_corresponding_points(pts_in_map, pts_in_frame))\n",
    "    indexes_frame = np.array(homographies)[:, 1]\n",
    "    for i in range(1, frame_to_process + 1):\n",
    "        if i in indexes_frame:\n",
    "            continue\n",
    "        else:\n",
    "            # get nearest frame \n",
    "            difference_array = np.absolute(indexes_frame-i)\n",
    "            near_value = int(indexes_frame[difference_array.argmin()])\n",
    "            # get the homographie between nearest point and current frame\n",
    "            if i < near_value:\n",
    "                index = np.where(np.all(homographies_between_frames[:, 0:2] == [i, near_value], axis=1))[0][0]\n",
    "            else: \n",
    "                index = np.where(np.all(homographies_between_frames[:, 0:2] == [near_value, i], axis=1))[0][0]\n",
    "            homography_i_to_near_value = homographies_between_frames[index, 2:].reshape(3, 3)\n",
    "\n",
    "            # compute compose homography\n",
    "            homography_near_value_to_map = homographies[np.where(indexes_frame == near_value)[0][0], 2:].reshape(3,3)\n",
    "            homography = [0, i]\n",
    "            homography.extend(np.array(homography_near_value_to_map @ homography_i_to_near_value).flatten())\n",
    "            homographies = np.vstack((homographies, homography))\n",
    "    return homographies\n",
    "\n",
    "if config['transforms'][0][0] == 'homography':\n",
    "    if config['transforms'][0][1] == 'all':\n",
    "        homographies = homographies_from_features(features, frames_to_process)\n",
    "    elif config['transforms'][0][1] == 'map':\n",
    "        if len(config['pts_in_map']) != len(config['pts_in_frame']):\n",
    "            print(\"Different amount of pts_in_map and pts_in_frame defined inside the config file\")\n",
    "            sys.exit(1)\n",
    "        homographies = homographies_from_map(features, frames_to_process, config['pts_in_map'], config['pts_in_frame'])\n",
    "        print(homographies)\n",
    "    data={'transforms': np.array(homographies).transpose()}\n",
    "    io.savemat(config['transforms_out'], data)\n",
    "else:\n",
    "    print(\"The only acceptable type is \\\"homography\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing RANSAC to remove outliers\n",
    "WORKING..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_homography_custom(src_points, dst_points, i, j, iterations=100, threshold=5.0):\n",
    "    src_points = np.array(src_points)\n",
    "    dst_points = np.array(dst_points)\n",
    "    best_homography = None\n",
    "    max_inliers = 0\n",
    "    n_points = src_points.shape[0]\n",
    "    best_projects = None\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # Randomly select 4 points for homography computation\n",
    "        indices = np.random.choice(n_points, 4, replace=False)\n",
    "        src_sample = src_points[indices]\n",
    "        dst_sample = dst_points[indices]\n",
    "\n",
    "        \n",
    "        # Estimate homography using these points\n",
    "        try:\n",
    "            H = create_homography_matrix(src_sample, dst_sample)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Project src_points using the estimated homography\n",
    "        ones = np.ones((n_points, 1))\n",
    "        homogeneous_src_points = np.hstack([src_points, ones])\n",
    "        projected_points = (H @ homogeneous_src_points.T).T\n",
    "        projected_points = projected_points[:, :2] / projected_points[:, [2]]\n",
    "\n",
    "        # Calculate distances between projected and actual destination points\n",
    "        distances = np.sqrt(np.sum((projected_points - dst_points) ** 2, axis=1))\n",
    "\n",
    "        # Count inliers\n",
    "        inliers_count = np.sum(distances < threshold)\n",
    "\n",
    "        # Update the best homography matrix if more inliers are found\n",
    "        if inliers_count > max_inliers:\n",
    "            best_homography = H.copy()\n",
    "            max_inliers = inliers_count\n",
    "            best_projects = projected_points\n",
    "            print(f'max_inliers: {max_inliers}')\n",
    "\n",
    "        # img_i = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "        # img_j = cv2.cvtColor(frames[j], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # # Warp img_i to img_j using the computed homography\n",
    "        # img_i_warped = cv2.warpPerspective(img_i, H, (img_j.shape[1], img_j.shape[0]))\n",
    "\n",
    "        # # Concatenate the two images side by side for visualization\n",
    "        # concatenated_imgs = np.concatenate((img_j, img_i_warped), axis=1)\n",
    "        # h, w = concatenated_imgs.shape\n",
    "        # concatenated_imgs = cv2.resize(concatenated_imgs, (int(1*w/2), int(1*h/2)), interpolation = cv2.INTER_LINEAR)\n",
    "        # cv2.imshow(f\"Homography RANSAC\", concatenated_imgs)\n",
    "\n",
    "    # Re-estimate homography using all inliers if a model was found\n",
    "    if best_homography is not None:\n",
    "        inliers = np.sqrt(np.sum((best_projects - dst_points) ** 2, axis=1)) < threshold\n",
    "        best_homography = create_homography_matrix(src_points[inliers], dst_points[inliers])\n",
    "\n",
    "    return np.array(best_homography), inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def homographies_from_features(features, frames_to_process):\n",
    "    homographies = []\n",
    "    for i in range(frames_to_process):\n",
    "        for j in range(i+1, frames_to_process):\n",
    "            matches, confidences = match_features(np.transpose(features[0, i][2:]), np.transpose(features[0, j][2:]), matches_size=100)\n",
    "\n",
    "            src_points = []\n",
    "            dst_points = []\n",
    "\n",
    "            for match in matches:\n",
    "                src_points.append(features[0, i][0:2, match.queryIdx])\n",
    "                dst_points.append(features[0, j][0:2, match.trainIdx])\n",
    "                \n",
    "            homography = [i+1, j+1]\n",
    "            homography_matrix, _ = ransac_homography_custom(src_points, dst_points, i, j, 5000)\n",
    "            Homography_cv, mask = cv2.findHomography(np.array(src_points), np.array(dst_points), cv2.RANSAC, 5.0)\n",
    "            \n",
    "            homography.extend(homography_matrix.flatten())\n",
    "            homographies.append(homography)\n",
    "            \n",
    "            matched_img = cv2.drawMatches(frames[i], keypoints_array[i], frames[j], keypoints_array[j], matches, None, flags=2)\n",
    "            h, w, _ = matched_img.shape\n",
    "            matched_img = cv2.resize(matched_img, (int(3*w/4), int(3*h/4)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.putText(matched_img, f\"{i}, {j}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.imwrite(f\"./debugfiles/matches/{config['videos'].split('.mp4')[0].split('/')[1]}_matches_frame_{i+1}_{j+1}_R.png\", matched_img)\n",
    "            cv2.imshow('Matches', matched_img)\n",
    "\n",
    "            img_i = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "            img_j = cv2.cvtColor(frames[j], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Warp img_i to img_j using the computed homography\n",
    "            img_i_warped = cv2.warpPerspective(img_j, homography_matrix, (img_j.shape[1], img_j.shape[0]))\n",
    "            img_open_cv = cv2.warpPerspective(img_j, Homography_cv, (img_j.shape[1], img_j.shape[0]))\n",
    "\n",
    "            cv2.putText(img_i, \"Original image\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(img_i_warped, \"Custom H\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(img_open_cv, \"Open CV H\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            # Concatenate the two images side by side for visualization\n",
    "            concatenated_imgs = np.concatenate((img_i, img_i_warped, img_open_cv), axis=1)\n",
    "            h, w = concatenated_imgs.shape\n",
    "            concatenated_imgs = cv2.resize(concatenated_imgs, (int(1*w/2), int(1*h/2)), interpolation = cv2.INTER_LINEAR)\n",
    "            cv2.imwrite(f\"./debugfiles/homography/{config['videos'].split('.mp4')[0].split('/')[1]}_homography_frame_{i+1}_{j+1}_R.png\", concatenated_imgs)\n",
    "            cv2.imshow(f\"Homography\", concatenated_imgs)\n",
    "            \n",
    "            if cv2.waitKey(60) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    return homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `compute_transform.py` main now with RANSAC\n",
    "\n",
    "WORKING..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_13656\\42020907.py:26: RuntimeWarning: invalid value encountered in divide\n",
      "  projected_points = projected_points[:, :2] / projected_points[:, [2]]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'inliers' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhomography\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m         homographies \u001b[38;5;241m=\u001b[39m \u001b[43mhomographies_from_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_to_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpts_in_map\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpts_in_frame\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "Cell \u001b[1;32mIn[69], line 16\u001b[0m, in \u001b[0;36mhomographies_from_features\u001b[1;34m(features, frames_to_process)\u001b[0m\n\u001b[0;32m     13\u001b[0m     dst_points\u001b[38;5;241m.\u001b[39mappend(features[\u001b[38;5;241m0\u001b[39m, j][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m, match\u001b[38;5;241m.\u001b[39mtrainIdx])\n\u001b[0;32m     15\u001b[0m homography \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 16\u001b[0m homography_matrix, _ \u001b[38;5;241m=\u001b[39m \u001b[43mransac_homography_custom\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m Homography_cv, mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindHomography(np\u001b[38;5;241m.\u001b[39marray(src_points), np\u001b[38;5;241m.\u001b[39marray(dst_points), cv2\u001b[38;5;241m.\u001b[39mRANSAC, \u001b[38;5;241m5.0\u001b[39m)\n\u001b[0;32m     19\u001b[0m homography\u001b[38;5;241m.\u001b[39mextend(homography_matrix\u001b[38;5;241m.\u001b[39mflatten())\n",
      "Cell \u001b[1;32mIn[68], line 58\u001b[0m, in \u001b[0;36mransac_homography_custom\u001b[1;34m(src_points, dst_points, i, j, iterations, threshold)\u001b[0m\n\u001b[0;32m     55\u001b[0m     inliers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum((best_projects \u001b[38;5;241m-\u001b[39m dst_points) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m<\u001b[39m threshold\n\u001b[0;32m     56\u001b[0m     best_homography \u001b[38;5;241m=\u001b[39m create_homography_matrix(src_points[inliers], dst_points[inliers])\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(best_homography), \u001b[43minliers\u001b[49m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'inliers' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "config_path = \"./conf_file.cpg\"\n",
    "config = parse_config_file(config_path)\n",
    "\n",
    "if config['transforms'][0][0] == 'homography':\n",
    "    if config['transforms'][0][1] == 'all':\n",
    "        homographies = homographies_from_features( features, frames_to_process)\n",
    "    elif config['transforms'][0][1] == 'map':\n",
    "        if len(config['pts_in_map']) != len(config['pts_in_frame']):\n",
    "            print(\"Different amount of pts_in_map and pts_in_frame defined inside the config file\")\n",
    "            sys.exit(1)\n",
    "        homographies = homographies_from_corresponding_points(config['pts_in_map'], config['pts_in_frame'])\n",
    "    data={'transforms': np.array(homographies).transpose()}\n",
    "    io.savemat(config['transforms_out'], data)\n",
    "else:\n",
    "    print(\"The only acceptable type is \\\"homography\\\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
